<html lang="en"><head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <title>GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields</title>
</head>

<body>
<div class="container">
    <br>
    <div style="text-align: center;">
        <h1>Mask-NeRF:</h1>
        <h3>Neural Radiance Fields for Masked Image Restoration</h3>
<!--        <div style="margin-bottom: 10px;">-->
<!--            <span style="margin-right: 10px; font-size: 1.2em;">Michael Niemeyer</span> <span style="font-size: 1.2em;">Andreas Geiger</span>-->
<!--        </div>-->
<!--        <div>-->
<!--        <span style="margin-right: 10px; font-size: 1.2em;">Max Planck Institute for Intelligent Systems and University-->
<!--          of TÃ¼bingen</span>-->
<!--        </div>-->
<!--        <div>-->
<!--            <span style="margin-right: 10px; font-size: 1.2em;">CVPR 2021 (oral, <strong>best paper award</strong>)</span>-->
<!--        </div>        -->
        <div>
            <span style="margin-right: 10px; font-size: 1.2em;">Anonymous CVPR submission</span>
        </div>
    </div>
    <div class="text-center" style="margin-top: 60px; margin-bottom: 20px;">
        <img src="gfx/overview.svg" class="img-fluid" alt="Responsive image" width="60%">
    </div>
    <div class="text-center" style="font-size: 1.5em; margin-bottom: 30px;">
        <a href="http://www.cvlibs.net/publications/Niemeyer2021CVPR.pdf" target="_blank" style="margin-right: 20px;">[Paper]</a>
        <a href="http://www.cvlibs.net/publications/Niemeyer2021CVPR_supplementary.pdf" target="_blank" style="margin-right: 20px;">[Supplementary]</a>
        <a href="https://github.com/autonomousvision/giraffe" target="_blank" style="margin-right: 20px;">[Code]</a>
        <a href="http://autonomousvision.github.io/giraffe" target="_blank" style="margin-right: 20px;">[Blog]</a>
        <a href="http://www.youtube.com/watch?v=fIaDXC-qRSg&amp;vq=hd1080&amp;autoplay=1" target="_blank" style="margin-right: 20px;">[Video]</a>
        <a href="https://m-niemeyer.github.io/slides/talks/giraffe/index.html" target="_blank" style="margin-right: 20px;">[Interactive Slides]</a>
        <a href="https://www.youtube.com/watch?v=scnXyCSMJF4" target="_blank">[Talk]</a>
    </div>
    <div>
        <h2 class="text-center">
            Abstract
        </h2>
        <p style="font-style: italic;">
            Deep generative models allow for photorealistic image synthesis at high resolutions. But for many applications,
            this is not enough: content creation also needs to be controllable. While several recent works investigate how
            to disentangle underlying factors of variation in the data, most of them operate in 2D and hence ignore that our
            world is three-dimensional. Further, only few works consider the compositional nature of scenes. Our key
            hypothesis is that incorporating a compositional 3D scene representation into the generative model leads to more
            controllable image synthesis. Representing scenes as compositional generative neural feature fields allows us to
            disentangle one or multiple objects from the background as well as individual objects' shapes and appearances
            while learning from unstructured and unposed image collections without any additional supervision. Combining
            this scene representation with a neural rendering pipeline yields a fast and realistic image synthesis model. As
            evidenced by our experiments, our model is able to disentangle individual objects and allows for translating and
            rotating them in the scene as well as changing the camera pose.
        </p>
        <p>
            <span style="font-weight: bold;">TL;DR:</span> We incorporate a compositional 3D scene representation into the generative model which leads to more controllable image synthesis.
        </p>
    </div>
    <div style="margin-top:10px;">
        <h2 class="text-center">
            Video
        </h2>
        <div class="embed-responsive embed-responsive-16by9">
            <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/fIaDXC-qRSg" allowfullscreen=""></iframe>
        </div>
    </div>
    <div style="margin-top:20px;">
        <h2 class="text-center">
            Results
        </h2>
        <h4>Comparison Against a 2D-based GAN</h4>
        <p>
            Note how translating one object affects the other for a 2D-based GAN. In contrast, we incorporate <span style="font-weight: bold;">compositional 3D scene structure</span> into the generative model, leading to more
            consistent results.</p>
        <div class="row">
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/clevr/2dgan.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Single-Object Translation for 2D-based GAN</p>
                </div>
            </div>
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/clevr/ours.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Single-Object Translation for Our Method</p>
                </div>
            </div>
        </div>
        <p>We can perform more complex operations like circular translations or adding objects at test time.</p>
        <div class="row">
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/clevr/translation_circle_sm.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Circular Translations</p>
                </div>
            </div>
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/clevr/add_objects.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Add Objects (Trained on Two-Object Scenes)</p>
                </div>
            </div>
        </div>
        <h4>Controllable Scene Generation</h4>
        <p>We show more examples where we control the scene during image synthesis.</p>
        <div class="row">
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/cars/rotation_object_sm.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Rotate Object</p>
                </div>
            </div>
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/celebahq/rotate_celebahq.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Rotate Object</p>
                </div>
            </div>
        </div>
        <div class="row">
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/cars/translation_horizontal_sm.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Horizontal Translation</p>
                </div>
            </div>
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/cars/translation_vertical_sm.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Vertical Translation</p>
                </div>
            </div>
        </div>
        <div class="row">
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/cars/cars_app.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Change Object Appearance</p>
                </div>
            </div>
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/celebahq/app_celebahq.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Change Object Appearance</p>
                </div>
            </div>
        </div>
        <div class="row">
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/cars/bg_cars.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Change Background Appearance</p>
                </div>
            </div>
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/churches/interpolate_appearance_bg_sm.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Change Background Appearance</p>
                </div>
            </div>
        </div>
        <h4>Out-of-Distribution Generalization</h4>
        <p>As our model disentangles individual objects, we are able to generate out of distribution samples. For example, we can increase the horizontal translation range.</p>
        <div class="row">
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/cars/translation_horizontal_sm.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Training Distribution</p>
                </div>
            </div>
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/outof/translation_horizontal_sm.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Out-Of-Distribution</p>
                </div>
            </div>
        </div>
        <p>We can increase the depth translation range.</p>
        <div class="row">
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/cars/translation_vertical_sm.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Training Distribution</p>
                </div>
            </div>
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/outof/translation_vertical_sm.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Out-Of-Distribution</p>
                </div>
            </div>
        </div>
        <p>We can add more objects at test time.</p>
        <div class="row">
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/clevr/add_objects.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Out-Of Distribution (Trained On Two-Object Scenes)</p>
                </div>
            </div>
            <div class="col-md-6 col-sm-6 col-xs-12 gallery">
                <div class="embed-responsive embed-responsive-16by9">
                    <video controls="" loop="" muted="" autoplay="" class="embed-responsive-item">
                        <source src="gfx/outof/add_objects.webm" type="video/webm">
                    </video>
                </div>
                <div class="text-center">
                    <p>Out-Of Distribution (Trained On One-Object Scenes)</p>
                </div>
            </div>
        </div>
    </div>
    <div>
        <h2 class="text-center">
            Citation
        </h2>
        <p>
            If you want to cite our work, please use:
        </p>
        <pre>        @inproceedings{Niemeyer2020GIRAFFE,
          author    = {Michael Niemeyer and Andreas Geiger},
          title     = {GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields},
          booktitle   = {Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
          year      = {2021},
        }
      </pre>
    </div>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>



</div></body></html>